{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "024fb9dd-a8fa-4f5f-8662-069e360adbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import mmcv\n",
    "from mmdet.apis import init_detector\n",
    "from mmocr.apis.inference import model_inference\n",
    "from mmocr.core.visualize import det_recog_show_result\n",
    "from mmocr.datasets.pipelines.crop import crop_img\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0eba7dc-8a92-4e13-bc4c-864fe4dc1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build recog model\n",
    "recog_ckpt = \"crnn_academic-a723a1c5.pth\"\n",
    "recog_config = \"crnn_academic_dataset.py\"\n",
    "device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669cb175-214c-40a5-bdb7-b2be03452a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "recog_model = init_detector(\n",
    "    recog_config, recog_ckpt, device=device)\n",
    "if hasattr(recog_model, 'module'):\n",
    "    recog_model = recog_model.module\n",
    "# if recog_model.cfg.data.test['type'] == 'ConcatDataset':\n",
    "#     recog_model.cfg.data.test.pipeline = \\\n",
    "#         recog_model.cfg.data.test['datasets'][0].pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9407aa13-4021-4f5b-96e8-da66c8926a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(pil_im, dst_height=32, dst_min_width=32, width_downsample_ratio=1.0 / 16):\n",
    "\n",
    "    (ori_width, ori_height) = pil_im.size\n",
    "    new_width = math.ceil(float(dst_height) / ori_height * ori_width)\n",
    "    width_divisor = int(1 / width_downsample_ratio)\n",
    "\n",
    "    if new_width % width_divisor != 0:\n",
    "        new_width = round(new_width / width_divisor) * width_divisor\n",
    "    \n",
    "    new_width = max(dst_min_width, new_width)\n",
    "    \n",
    "    im_resized = pil_im.resize(size=(new_width, dst_height))\n",
    "    \n",
    "    return np.asarray(im_resized, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96191020-9c27-49fe-af68-8beef6177ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39, 32)\n",
      "(32, 32)\n",
      "torch.Size([1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "image = \"test_images/image_2.jpg\"\n",
    "\n",
    "pil_im = Image.open(image).convert('L')\n",
    "print(pil_im.size)\n",
    "im_array = preprocess_image(pil_im)\n",
    "print(im_array.shape)\n",
    "\n",
    "im_array = (im_array-127.0)/127.0\n",
    "\n",
    "image_tensor = torch.from_numpy(im_array)\n",
    "image_tensor = image_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46318879-5cef-44ad-980a-2d99e658bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict(img=image_tensor.unsqueeze(0), img_metas=[{'filename': 'test_images/image_1.jpg', 'resize_shape': (32, 48), 'valid_ratio': 1.0}])\n",
    "with torch.no_grad():\n",
    "    det_result = recog_model(return_loss=False, rescale=True, **data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9137339-184e-4182-ba77-1e42ded4051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '29', 'score': [0.7329947352409363, 0.5580153465270996]}]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_array = np.asarray(pil_im)\n",
    "plt.imshow(im_array)\n",
    "print(det_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e26fc7d-4cc0-444c-830c-32924ec705cc",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25303940-fe36-45c2-a87c-4bcd7866005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import CRNNNet, VeryDeepVgg\n",
    "from mmocr.models.textrecog import CTCConvertor, CTCLoss, CRNNDecoder\n",
    "from mmcv.runner import load_checkpoint\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a174affa-a7c8-427b-8e15-3d2bdd2f59f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = mmcv.Config.fromfile(recog_config)\n",
    "model_config = config.model\n",
    "# print(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17a5eec0-328b-48a0-a25e-0d1a909c1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len=40\n",
    "\n",
    "backbone_cfg = model_config['backbone'].copy()\n",
    "backbone_cfg.pop('type')\n",
    "backbone = VeryDeepVgg(**backbone_cfg)\n",
    "\n",
    "\n",
    "label_converter_cfg = model_config['label_convertor'].copy()\n",
    "label_converter_cfg.pop('type')\n",
    "label_converter_cfg.update(max_seq_len=max_seq_len)\n",
    "label_converter = CTCConvertor(**label_converter_cfg)\n",
    "\n",
    "decoder_cfg = model_config['decoder'].copy()\n",
    "decoder_cfg.pop('type')\n",
    "decoder_cfg.update(num_classes=label_converter.num_classes())\n",
    "decoder_cfg.update(start_idx=label_converter.start_idx)\n",
    "decoder_cfg.update(padding_idx=label_converter.padding_idx)\n",
    "decoder_cfg.update(max_seq_len=max_seq_len)\n",
    "decoder = CRNNDecoder(**decoder_cfg)\n",
    "\n",
    "\n",
    "loss_cfg = model_config['decoder'].copy()\n",
    "loss_cfg.pop('type')\n",
    "loss_cfg.update(ignore_index=label_converter.padding_idx)\n",
    "loss = CTCLoss(**loss_cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313193a7-3f21-429d-9546-19b5086bf44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.load_state_dict(recog_model.backbone.state_dict())\n",
    "decoder.load_state_dict(recog_model.decoder.state_dict())\n",
    "\n",
    "model = CRNNNet(preprocessor=None,\n",
    "            backbone=backbone,\n",
    "            decoder=decoder,\n",
    "            loss=loss,\n",
    "            label_convertor=label_converter,\n",
    "            pretrained=None,\n",
    "            test_cfg=config.get('test_cfg'))\n",
    "# model.backbone.load_state_dict(recog_model.backbone.state_dict())\n",
    "# model.decoder.load_state_dict(recog_model.decoder.state_dict())\n",
    "# model.load_state_dict(torch.load(recog_ckpt)['state_dict'])\n",
    "# map_loc = 'cpu' if device == 'cpu' else None\n",
    "# checkpoint = load_checkpoint(model, recog_ckpt, map_location=map_loc)\n",
    "# if 'CLASSES' in checkpoint.get('meta', {}):\n",
    "#     model.CLASSES = checkpoint['meta']['CLASSES']\n",
    "# _ = model.to(device)\n",
    "model.eval()\n",
    "model.cfg = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e198317-eedf-4ae8-83dd-3edc45053c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': '29', 'score': [0.7329947352409363, 0.5580153465270996]}]\n"
     ]
    }
   ],
   "source": [
    "# with torch.no_grad():\n",
    "det_result = model(return_loss=False, rescale=True, **data)\n",
    "    \n",
    "print(det_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0a7e7-cd3a-49ff-b6c2-1680f54111ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuser_list = [\n",
    "    [\"backbone.cnn.conv0\", \"backbone.cnn.relu0\"],\n",
    "    [\"backbone.cnn.conv1\", \"backbone.cnn.relu1\"],\n",
    "    [\"backbone.cnn.conv2\", \"backbone.cnn.batchnorm2\", \"backbone.cnn.relu2\"],\n",
    "    [\"backbone.cnn.conv3\", \"backbone.cnn.relu3\"],\n",
    "    [\"backbone.cnn.conv4\", \"backbone.cnn.batchnorm4\", \"backbone.cnn.relu4\"],\n",
    "    [\"backbone.cnn.conv5\", \"backbone.cnn.relu5\"],\n",
    "    [\"backbone.cnn.conv6\", \"backbone.cnn.batchnorm6\", \"backbone.cnn.relu6\"]\n",
    "]\n",
    "fused_model = torch.quantization.fuse_modules(copy.deepcopy(model), fuser_list, inplace=True)\n",
    "fused_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f2e756-4740-45c0-9710-5d15765d3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b78736-eef8-4f04-99c6-ce6f34ebd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    det_result = fused_model(return_loss=False, rescale=True, **data)\n",
    "    \n",
    "print(det_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85022bd4-4ef9-435a-adea-fd41329296d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_torchscript_model(model, model_dir, model_filename):\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_filepath = os.path.join(model_dir, model_filename)\n",
    "    torch.jit.save(torch.jit.script(model), model_filepath)\n",
    "\n",
    "def load_torchscript_model(model_filepath, device):\n",
    "    model = torch.jit.load(model_filepath, map_location=device)\n",
    "    return model\n",
    "\n",
    "def calibrate_model(model, device=torch.device(\"cpu:0\")):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(3):\n",
    "        _ = model(return_loss=False, rescale=True, **data)\n",
    "#     for inputs, labels in loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         labels = labels.to(device)\n",
    "#         _ = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc73fd-8215-40ab-958e-716ed9fa82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = torch.device(\"cpu:0\")\n",
    "model_dir = \"quantized\"\n",
    "quantized_model_filename = \"crnn_quantized_int8.ptl\"\n",
    "\n",
    "image = \"test_images/image_2.jpg\"\n",
    "\n",
    "pil_im = Image.open(image).convert('L')\n",
    "print(pil_im.size)\n",
    "im_array = preprocess_image(pil_im)\n",
    "print(im_array.shape)\n",
    "\n",
    "im_array = (im_array-127.0)/127.0\n",
    "\n",
    "image_tensor = torch.from_numpy(im_array)\n",
    "image_tensor = image_tensor.unsqueeze(0).to(cpu_device)\n",
    "data = dict(img=image_tensor.unsqueeze(0), img_metas=[{'filename': 'test_images/image_1.jpg', 'resize_shape': (32, 48), 'valid_ratio': 1.0}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27ca64-ea3c-46cd-a0ee-733d0a64a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantization_config = torch.quantization.get_default_qconfig(\"fbgemm\") # or 'qnnpack'\n",
    "quantization_config = torch.quantization.get_default_qconfig('qnnpack') # or 'qnnpack'\n",
    "fused_model.qconfig = quantization_config\n",
    "\n",
    "print(fused_model.qconfig)\n",
    "\n",
    "torch.quantization.prepare(fused_model, inplace=True)\n",
    "\n",
    "calibrate_model(model=fused_model, device=cpu_device)\n",
    "\n",
    "quantized_model = torch.quantization.convert(fused_model, inplace=True)\n",
    "\n",
    "quantized_model.eval()\n",
    "\n",
    "# Print quantized model.\n",
    "# print(quantized_model)\n",
    "\n",
    "# Save quantized model.\n",
    "save_torchscript_model(model=quantized_model, model_dir=model_dir, model_filename=quantized_model_filename)\n",
    "\n",
    "# Load quantized model.\n",
    "quantized_jit_model = load_torchscript_model(model_filepath=quantized_model_filepath, device=cpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ad002-5886-488d-9dca-3fd51bff4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     det_result = quantized_jit_model(return_loss=False, rescale=True, **data)\n",
    "    det_result = quantized_jit_model(return_loss=False, rescale=True, **data)\n",
    "    \n",
    "print(det_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
